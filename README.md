# Januar-3-uger-Knowledge-Distillation
Gruppe 13 januar 3 ugers kode.

Needed packages are pytorch, numpy and matplotlib.

the code will download the cifar-10 dataset and put it in a "data" folder. all the data is approximately 350MB

The main function is the distillation function.
To train the model directly on the training data set "standard_loss_weight" to 1 and "distillation_loss_weight" to 0. else choose each weight as wanted.

